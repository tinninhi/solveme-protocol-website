#!/usr/bin/env python3
"""
V4.0 è®¤çŸ¥ç–«è‹—æœºåˆ¶ - Cognitive Vaccine
Cognitive Vaccine Mechanism for V4.0 Protocol

å®ç°è®¤çŸ¥é™ç»´åŒ…å’Œæƒ…ç»ªç¼“å†²ç»“æ„ï¼Œä¿æŠ¤äººç±»è®¤çŸ¥èƒ½åŠ›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import json
import time
import re


class CognitiveLevel(Enum):
    """è®¤çŸ¥ç­‰çº§æšä¸¾"""
    INFANT = "infant"           # å©´å„¿çº§
    CHILD = "child"             # å„¿ç«¥çº§
    TEEN = "teen"               # é’å°‘å¹´çº§
    ADULT = "adult"             # æˆå¹´çº§
    EXPERT = "expert"           # ä¸“å®¶çº§


class EmotionalIntensity(Enum):
    """æƒ…ç»ªå¼ºåº¦æšä¸¾"""
    CALM = "calm"              # å¹³é™
    MILD = "mild"              # è½»å¾®
    MODERATE = "moderate"      # ä¸­ç­‰
    INTENSE = "intense"        # å¼ºçƒˆ
    OVERWHELMING = "overwhelming"  # å‹å€’æ€§


@dataclass
class VaccinatedContent:
    """æ¥ç§ç–«è‹—åçš„å†…å®¹"""
    original_content: str
    vaccinated_content: str
    cognitive_level: CognitiveLevel
    emotional_intensity: EmotionalIntensity
    vaccine_applied: List[str]
    confidence_score: float


class CognitiveDowngrade(nn.Module):
    """è®¤çŸ¥é™ç»´åŒ…"""
    
    def __init__(self, hidden_size: int = 768):
        super().__init__()
        self.hidden_size = hidden_size
        
        # è®¤çŸ¥å¤æ‚åº¦è¯„ä¼°å™¨
        self.cognitive_complexity_assessor = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # è®¤çŸ¥é™ç»´å™¨
        self.cognitive_downgrader = nn.Sequential(
            nn.Linear(hidden_size, hidden_size * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size * 2, hidden_size),
            nn.LayerNorm(hidden_size)
        )
        
        # ç®€åŒ–è¯æ±‡æ˜ å°„
        self.simplification_mapping = {
            # å¤æ‚è¯æ±‡ -> ç®€å•è¯æ±‡
            "sophisticated": "advanced",
            "elaborate": "detailed", 
            "comprehensive": "complete",
            "theoretical": "concept",
            "empirical": "practical",
            "methodological": "method",
            "analytical": "analysis",
            "systematic": "organized",
            "paradigm": "model",
            "framework": "structure"
        }
        
        # å¤æ‚å¥å¼æ¨¡å¼
        self.complex_patterns = [
            r"notwithstanding the fact that",
            r"in light of the aforementioned",
            r"it is imperative to note that",
            r"furthermore, it should be emphasized",
            r"consequently, it follows that"
        ]
        
        # ç®€åŒ–å¥å¼æ›¿æ¢
        self.simple_replacements = [
            "although",
            "given this",
            "it's important that",
            "also,",
            "so,"
        ]
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for layer in self.cognitive_complexity_assessor:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
        
        for layer in self.cognitive_downgrader:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
    
    def forward(self, content_embedding: torch.Tensor, text: str, target_level: CognitiveLevel = CognitiveLevel.ADULT) -> Tuple[str, Dict[str, Any]]:
        """
        åº”ç”¨è®¤çŸ¥é™ç»´
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            text: åŸå§‹æ–‡æœ¬
            target_level: ç›®æ ‡è®¤çŸ¥ç­‰çº§
            
        Returns:
            é™ç»´åçš„æ–‡æœ¬
            é™ç»´åˆ†æä¿¡æ¯
        """
        # è¯„ä¼°åŸå§‹è®¤çŸ¥å¤æ‚åº¦
        original_complexity = self.cognitive_complexity_assessor(content_embedding).item()
        
        # æ ¹æ®ç›®æ ‡ç­‰çº§ç¡®å®šé™ç»´å¼ºåº¦
        downgrade_intensity = self._get_downgrade_intensity(target_level)
        
        # åº”ç”¨è¯æ±‡ç®€åŒ–
        simplified_text = self._simplify_vocabulary(text)
        
        # åº”ç”¨å¥å¼ç®€åŒ–
        simplified_text = self._simplify_sentences(simplified_text)
        
        # åº”ç”¨ç»“æ„ç®€åŒ–
        simplified_text = self._simplify_structure(simplified_text)
        
        # è¯„ä¼°é™ç»´æ•ˆæœ
        downgrade_analysis = {
            'original_complexity': original_complexity,
            'target_level': target_level.value,
            'downgrade_intensity': downgrade_intensity,
            'vocabulary_simplified': len(self._get_simplified_words(text)) > 0,
            'sentences_simplified': len(self._get_simplified_sentences(text)) > 0,
            'structure_simplified': len(self._get_simplified_structures(text)) > 0
        }
        
        return simplified_text, downgrade_analysis
    
    def _get_downgrade_intensity(self, target_level: CognitiveLevel) -> float:
        """è·å–é™ç»´å¼ºåº¦"""
        intensity_mapping = {
            CognitiveLevel.INFANT: 0.9,
            CognitiveLevel.CHILD: 0.7,
            CognitiveLevel.TEEN: 0.5,
            CognitiveLevel.ADULT: 0.3,
            CognitiveLevel.EXPERT: 0.1
        }
        return intensity_mapping.get(target_level, 0.3)
    
    def _simplify_vocabulary(self, text: str) -> str:
        """ç®€åŒ–è¯æ±‡"""
        simplified_text = text
        
        # åº”ç”¨è¯æ±‡æ˜ å°„
        for complex_word, simple_word in self.simplification_mapping.items():
            pattern = r'\b' + re.escape(complex_word) + r'\b'
            simplified_text = re.sub(pattern, simple_word, simplified_text, flags=re.IGNORECASE)
        
        return simplified_text
    
    def _simplify_sentences(self, text: str) -> str:
        """ç®€åŒ–å¥å¼"""
        simplified_text = text
        
        # åº”ç”¨å¥å¼ç®€åŒ–
        for i, pattern in enumerate(self.complex_patterns):
            if i < len(self.simple_replacements):
                simplified_text = re.sub(pattern, self.simple_replacements[i], simplified_text, flags=re.IGNORECASE)
        
        return simplified_text
    
    def _simplify_structure(self, text: str) -> str:
        """ç®€åŒ–ç»“æ„"""
        # åˆ†å‰²é•¿å¥
        sentences = text.split('.')
        simplified_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 100:  # å¦‚æœå¥å­å¤ªé•¿
                # åœ¨é€—å·å¤„åˆ†å‰²
                parts = sentence.split(',')
                if len(parts) > 2:
                    # å–å‰ä¸¤éƒ¨åˆ†ä½œä¸ºç®€åŒ–å¥å­
                    simplified_sentence = ','.join(parts[:2]) + '.'
                    simplified_sentences.append(simplified_sentence)
                else:
                    simplified_sentences.append(sentence + '.')
            else:
                simplified_sentences.append(sentence + '.')
        
        return ' '.join(simplified_sentences)
    
    def _get_simplified_words(self, text: str) -> List[str]:
        """è·å–è¢«ç®€åŒ–çš„è¯æ±‡"""
        simplified_words = []
        for complex_word in self.simplification_mapping.keys():
            if complex_word.lower() in text.lower():
                simplified_words.append(complex_word)
        return simplified_words
    
    def _get_simplified_sentences(self, text: str) -> List[str]:
        """è·å–è¢«ç®€åŒ–çš„å¥å¼"""
        simplified_sentences = []
        for pattern in self.complex_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                simplified_sentences.append(pattern)
        return simplified_sentences
    
    def _get_simplified_structures(self, text: str) -> List[str]:
        """è·å–è¢«ç®€åŒ–çš„ç»“æ„"""
        long_sentences = []
        sentences = text.split('.')
        for sentence in sentences:
            if len(sentence.strip()) > 100:
                long_sentences.append(sentence.strip())
        return long_sentences


class EmotionBuffer(nn.Module):
    """æƒ…ç»ªç¼“å†²ç»“æ„"""
    
    def __init__(self, hidden_size: int = 768):
        super().__init__()
        self.hidden_size = hidden_size
        
        # æƒ…ç»ªå¼ºåº¦è¯„ä¼°å™¨
        self.emotional_intensity_assessor = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # æƒ…ç»ªç¼“å†²å™¨
        self.emotion_buffer = nn.Sequential(
            nn.Linear(hidden_size, hidden_size * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size * 2, hidden_size),
            nn.LayerNorm(hidden_size)
        )
        
        # æƒ…ç»ªå…³é”®è¯æ˜ å°„
        self.emotion_keywords = {
            'intense': ['overwhelming', 'devastating', 'terrifying', 'horrific', 'catastrophic'],
            'moderate': ['concerning', 'worrisome', 'troubling', 'disturbing', 'upsetting'],
            'mild': ['sad', 'disappointing', 'frustrating', 'annoying', 'bothersome'],
            'calm': ['peaceful', 'tranquil', 'serene', 'calm', 'gentle']
        }
        
        # æƒ…ç»ªç¼“å†²è¯æ±‡
        self.buffer_phrases = {
            'intense': ['è¯·æ³¨æ„ï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½è¾ƒä¸ºå¼ºçƒˆ', 'æé†’ï¼šå†…å®¹å¯èƒ½å¼•èµ·å¼ºçƒˆæƒ…ç»ªååº”'],
            'moderate': ['ä»¥ä¸‹å†…å®¹å¯èƒ½å¼•èµ·ä¸€äº›æƒ…ç»ªååº”', 'è¯·æ³¨æ„ï¼šå†…å®¹å¯èƒ½ä»¤äººä¸é€‚'],
            'mild': ['ä»¥ä¸‹å†…å®¹å¯èƒ½å¼•èµ·è½»å¾®æƒ…ç»ªååº”', 'æé†’ï¼šå†…å®¹å¯èƒ½ä»¤äººä¸å¿«'],
            'calm': ['ä»¥ä¸‹å†…å®¹ç›¸å¯¹å¹³é™', 'å†…å®¹è¾ƒä¸ºæ¸©å’Œ']
        }
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for layer in self.emotional_intensity_assessor:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
        
        for layer in self.emotion_buffer:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
    
    def forward(self, content_embedding: torch.Tensor, text: str) -> Tuple[str, Dict[str, Any]]:
        """
        åº”ç”¨æƒ…ç»ªç¼“å†²
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            ç¼“å†²åçš„æ–‡æœ¬
            ç¼“å†²åˆ†æä¿¡æ¯
        """
        # è¯„ä¼°æƒ…ç»ªå¼ºåº¦
        emotional_intensity = self.emotional_intensity_assessor(content_embedding).item()
        
        # ç¡®å®šæƒ…ç»ªç­‰çº§
        emotion_level = self._determine_emotion_level(emotional_intensity)
        
        # åº”ç”¨æƒ…ç»ªç¼“å†²
        buffered_text = self._apply_emotion_buffer(text, emotion_level)
        
        # ç¼“å†²åˆ†æ
        buffer_analysis = {
            'emotional_intensity': emotional_intensity,
            'emotion_level': emotion_level.value,
            'buffer_applied': emotion_level != EmotionalIntensity.CALM,
            'buffer_phrases_added': len(self._get_buffer_phrases(emotion_level)) > 0
        }
        
        return buffered_text, buffer_analysis
    
    def _determine_emotion_level(self, intensity: float) -> EmotionalIntensity:
        """ç¡®å®šæƒ…ç»ªç­‰çº§"""
        if intensity < 0.2:
            return EmotionalIntensity.CALM
        elif intensity < 0.4:
            return EmotionalIntensity.MILD
        elif intensity < 0.6:
            return EmotionalIntensity.MODERATE
        elif intensity < 0.8:
            return EmotionalIntensity.INTENSE
        else:
            return EmotionalIntensity.OVERWHELMING
    
    def _apply_emotion_buffer(self, text: str, emotion_level: EmotionalIntensity) -> str:
        """åº”ç”¨æƒ…ç»ªç¼“å†²"""
        if emotion_level == EmotionalIntensity.CALM:
            return text
        
        # è·å–ç¼“å†²çŸ­è¯­
        buffer_phrases = self._get_buffer_phrases(emotion_level)
        
        # æ·»åŠ ç¼“å†²çŸ­è¯­
        if buffer_phrases:
            buffer_text = buffer_phrases[0] + "\n\n"
            buffered_text = buffer_text + text
        else:
            buffered_text = text
        
        return buffered_text
    
    def _get_buffer_phrases(self, emotion_level: EmotionalIntensity) -> List[str]:
        """è·å–ç¼“å†²çŸ­è¯­"""
        level_key = emotion_level.value
        return self.buffer_phrases.get(level_key, [])


class CognitiveVaccine:
    """V4.0 è®¤çŸ¥ç–«è‹—æœºåˆ¶"""
    
    def __init__(self, hidden_size: int = 768):
        self.hidden_size = hidden_size
        
        # åˆå§‹åŒ–è®¤çŸ¥é™ç»´åŒ…å’Œæƒ…ç»ªç¼“å†²ç»“æ„
        self.cognitive_downgrade = CognitiveDowngrade(hidden_size)
        self.emotion_buffer = EmotionBuffer(hidden_size)
        
        # ç–«è‹—é…ç½®
        self.default_cognitive_level = CognitiveLevel.ADULT
        self.enable_emotion_buffer = True
        
        # ç–«è‹—åº”ç”¨å†å²
        self.vaccine_history = []
    
    def apply_vaccine(self, content_embedding: torch.Tensor, text: str, 
                     target_cognitive_level: CognitiveLevel = None,
                     enable_emotion_buffer: bool = None) -> VaccinatedContent:
        """
        åº”ç”¨è®¤çŸ¥ç–«è‹—
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            text: åŸå§‹æ–‡æœ¬
            target_cognitive_level: ç›®æ ‡è®¤çŸ¥ç­‰çº§
            enable_emotion_buffer: æ˜¯å¦å¯ç”¨æƒ…ç»ªç¼“å†²
            
        Returns:
            æ¥ç§ç–«è‹—åçš„å†…å®¹
        """
        # ä½¿ç”¨é»˜è®¤é…ç½®
        if target_cognitive_level is None:
            target_cognitive_level = self.default_cognitive_level
        if enable_emotion_buffer is None:
            enable_emotion_buffer = self.enable_emotion_buffer
        
        # åº”ç”¨è®¤çŸ¥é™ç»´åŒ…
        downgraded_text, downgrade_analysis = self.cognitive_downgrade(
            content_embedding, text, target_cognitive_level
        )
        
        # åº”ç”¨æƒ…ç»ªç¼“å†²ç»“æ„
        if enable_emotion_buffer:
            buffered_text, buffer_analysis = self.emotion_buffer(content_embedding, downgraded_text)
        else:
            buffered_text = downgraded_text
            buffer_analysis = {'buffer_applied': False}
        
        # ç¡®å®šæœ€ç»ˆè®¤çŸ¥ç­‰çº§å’Œæƒ…ç»ªå¼ºåº¦
        final_cognitive_level = self._determine_final_cognitive_level(downgrade_analysis)
        final_emotional_intensity = self._determine_final_emotional_intensity(buffer_analysis)
        
        # è®°å½•ç–«è‹—åº”ç”¨
        vaccine_applied = []
        if downgrade_analysis.get('vocabulary_simplified'):
            vaccine_applied.append('vocabulary_simplification')
        if downgrade_analysis.get('sentences_simplified'):
            vaccine_applied.append('sentence_simplification')
        if downgrade_analysis.get('structure_simplified'):
            vaccine_applied.append('structure_simplification')
        if buffer_analysis.get('buffer_applied'):
            vaccine_applied.append('emotion_buffer')
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_score = self._calculate_vaccine_confidence(downgrade_analysis, buffer_analysis)
        
        # åˆ›å»ºæ¥ç§ç–«è‹—åçš„å†…å®¹
        vaccinated_content = VaccinatedContent(
            original_content=text,
            vaccinated_content=buffered_text,
            cognitive_level=final_cognitive_level,
            emotional_intensity=final_emotional_intensity,
            vaccine_applied=vaccine_applied,
            confidence_score=confidence_score
        )
        
        # è®°å½•ç–«è‹—å†å²
        self._record_vaccine_application(vaccinated_content)
        
        return vaccinated_content
    
    def _determine_final_cognitive_level(self, downgrade_analysis: Dict[str, Any]) -> CognitiveLevel:
        """ç¡®å®šæœ€ç»ˆè®¤çŸ¥ç­‰çº§"""
        target_level = downgrade_analysis.get('target_level', 'adult')
        
        # æ ¹æ®é™ç»´å¼ºåº¦è°ƒæ•´è®¤çŸ¥ç­‰çº§
        downgrade_intensity = downgrade_analysis.get('downgrade_intensity', 0.3)
        
        if downgrade_intensity > 0.7:
            return CognitiveLevel.CHILD
        elif downgrade_intensity > 0.5:
            return CognitiveLevel.TEEN
        elif downgrade_intensity > 0.3:
            return CognitiveLevel.ADULT
        else:
            return CognitiveLevel.EXPERT
    
    def _determine_final_emotional_intensity(self, buffer_analysis: Dict[str, Any]) -> EmotionalIntensity:
        """ç¡®å®šæœ€ç»ˆæƒ…ç»ªå¼ºåº¦"""
        if buffer_analysis.get('buffer_applied', False):
            emotion_level = buffer_analysis.get('emotion_level', 'calm')
            return EmotionalIntensity(emotion_level)
        else:
            return EmotionalIntensity.CALM
    
    def _calculate_vaccine_confidence(self, downgrade_analysis: Dict[str, Any], 
                                    buffer_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—ç–«è‹—ç½®ä¿¡åº¦"""
        # åŸºäºç–«è‹—åº”ç”¨æ•ˆæœè®¡ç®—ç½®ä¿¡åº¦
        vaccine_effects = 0
        
        if downgrade_analysis.get('vocabulary_simplified'):
            vaccine_effects += 0.3
        if downgrade_analysis.get('sentences_simplified'):
            vaccine_effects += 0.3
        if downgrade_analysis.get('structure_simplified'):
            vaccine_effects += 0.2
        if buffer_analysis.get('buffer_applied'):
            vaccine_effects += 0.2
        
        return min(vaccine_effects, 1.0)
    
    def _record_vaccine_application(self, vaccinated_content: VaccinatedContent):
        """è®°å½•ç–«è‹—åº”ç”¨å†å²"""
        record = {
            'timestamp': time.time(),
            'original_length': len(vaccinated_content.original_content),
            'vaccinated_length': len(vaccinated_content.vaccinated_content),
            'cognitive_level': vaccinated_content.cognitive_level.value,
            'emotional_intensity': vaccinated_content.emotional_intensity.value,
            'vaccine_applied': vaccinated_content.vaccine_applied,
            'confidence_score': vaccinated_content.confidence_score
        }
        
        self.vaccine_history.append(record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.vaccine_history) > 1000:
            self.vaccine_history = self.vaccine_history[-500:]
    
    def get_vaccine_statistics(self) -> Dict[str, Any]:
        """è·å–ç–«è‹—åº”ç”¨ç»Ÿè®¡ä¿¡æ¯"""
        if not self.vaccine_history:
            return {"error": "No vaccine history available"}
        
        total_applications = len(self.vaccine_history)
        
        # è®¤çŸ¥ç­‰çº§åˆ†å¸ƒ
        cognitive_levels = [record['cognitive_level'] for record in self.vaccine_history]
        cognitive_distribution = {}
        for level in cognitive_levels:
            cognitive_distribution[level] = cognitive_distribution.get(level, 0) + 1
        
        # æƒ…ç»ªå¼ºåº¦åˆ†å¸ƒ
        emotional_intensities = [record['emotional_intensity'] for record in self.vaccine_history]
        emotional_distribution = {}
        for intensity in emotional_intensities:
            emotional_distribution[intensity] = emotional_distribution.get(intensity, 0) + 1
        
        # ç–«è‹—åº”ç”¨æ•ˆæœç»Ÿè®¡
        vaccine_effects = []
        for record in self.vaccine_history:
            if record['vaccine_applied']:
                vaccine_effects.append(len(record['vaccine_applied']))
        
        avg_vaccine_effects = sum(vaccine_effects) / len(vaccine_effects) if vaccine_effects else 0
        
        return {
            'total_applications': total_applications,
            'cognitive_level_distribution': cognitive_distribution,
            'emotional_intensity_distribution': emotional_distribution,
            'average_vaccine_effects': avg_vaccine_effects,
            'average_confidence_score': sum(record['confidence_score'] for record in self.vaccine_history) / total_applications
        }


def test_cognitive_vaccine():
    """æµ‹è¯•è®¤çŸ¥ç–«è‹—æœºåˆ¶"""
    print("ğŸ§ª æµ‹è¯•V4.0è®¤çŸ¥ç–«è‹—æœºåˆ¶...")
    
    # åˆ›å»ºè®¤çŸ¥ç–«è‹—
    vaccine = CognitiveVaccine()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'text': 'è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ–‡æœ¬ã€‚',
            'target_cognitive_level': CognitiveLevel.ADULT,
            'expected_result': 'simple'
        },
        {
            'text': 'è¿™æ˜¯ä¸€ä¸ªåŒ…å«å¤æ‚è¯æ±‡å’Œå¥å¼çš„æ–‡æœ¬ï¼Œéœ€è¦æ·±å…¥çš„ç†è®ºåˆ†æå’Œç³»ç»Ÿæ€§çš„æ–¹æ³•è®ºæ¡†æ¶æ¥ç†è§£å…¶å†…æ¶µã€‚',
            'target_cognitive_level': CognitiveLevel.CHILD,
            'expected_result': 'simplified'
        },
        {
            'text': 'è¿™æ˜¯ä¸€ä¸ªå¯èƒ½å¼•èµ·å¼ºçƒˆæƒ…ç»ªååº”çš„å†…å®¹ï¼ŒåŒ…å«ä»¤äººéœ‡æƒŠå’Œä¸å®‰çš„ä¿¡æ¯ã€‚',
            'target_cognitive_level': CognitiveLevel.ADULT,
            'expected_result': 'buffered'
        }
    ]
    
    for i, test_case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}:")
        print(f"åŸå§‹æ–‡æœ¬: {test_case['text']}")
        print(f"ç›®æ ‡è®¤çŸ¥ç­‰çº§: {test_case['target_cognitive_level'].value}")
        
        # åˆ›å»ºæ¨¡æ‹ŸåµŒå…¥
        content_embedding = torch.randn(1, 768)
        
        # åº”ç”¨è®¤çŸ¥ç–«è‹—
        vaccinated_content = vaccine.apply_vaccine(
            content_embedding,
            test_case['text'],
            test_case['target_cognitive_level']
        )
        
        print(f"æ¥ç§ç–«è‹—åæ–‡æœ¬: {vaccinated_content.vaccinated_content}")
        print(f"è®¤çŸ¥ç­‰çº§: {vaccinated_content.cognitive_level.value}")
        print(f"æƒ…ç»ªå¼ºåº¦: {vaccinated_content.emotional_intensity.value}")
        print(f"ç–«è‹—åº”ç”¨: {vaccinated_content.vaccine_applied}")
        print(f"ç½®ä¿¡åº¦: {vaccinated_content.confidence_score:.3f}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = vaccine.get_vaccine_statistics()
    print(f"\nğŸ“Š ç–«è‹—åº”ç”¨ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    test_cognitive_vaccine() 