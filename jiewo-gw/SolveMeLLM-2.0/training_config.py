#!/usr/bin/env python3
"""
æœ€å¼ºæ¨¡å‹è®­ç»ƒé…ç½®
Training configuration for the strongest model
"""

import json
from dataclasses import dataclass
from typing import Dict, Any, List

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    
    # æ¨¡å‹é…ç½®
    model_config = {
        'vocab_size': 50000,
        'hidden_size': 512,  # ä»768å‡å°‘åˆ°512
        'num_layers': 6,     # ä»12å‡å°‘åˆ°6
        'num_heads': 8,      # ä»12å‡å°‘åˆ°8
        'max_seq_length': 1024,  # ä»2048å‡å°‘åˆ°1024
        'dropout': 0.1,
        'activation': 'gelu',
        'layer_norm_eps': 1e-6,
        'pre_norm': True,
        'enable_clock_trigger': True,
        'clock_interval': 300,
        'enable_expression_arbitrator': True,
        'enable_cognitive_vaccine': True,
        'enable_self_iteration': True,
        'enable_active_learning': True
    }
    
    # è®­ç»ƒé…ç½®
    training_config = {
        'batch_size': 4,     # ä»8å‡å°‘åˆ°4
        'gradient_accumulation_steps': 4,
        'learning_rate': 1e-4,
        'weight_decay': 0.01,
        'warmup_steps': 1000,
        'max_steps': 100000,
        'max_epochs': 10,
        'jiewo_loss_weight': 0.1,
        'ethic_loss_weight': 0.2,
        'reflection_loss_weight': 0.1,
        'beta1': 0.9,
        'beta2': 0.999,
        'eps': 1e-8,
        'train_data_path': 'data/train_data.json',
        'val_data_path': 'data/val_data.json',
        'test_data_path': 'data/test_data.json',
        'save_steps': 5000,
        'eval_steps': 1000,
        'save_total_limit': 3,
        'local_rank': -1,
        'distributed': False,
        'fp16': False,
        'fp16_opt_level': 'O1',
        'logging_steps': 100,
        'log_level': 'INFO',
        'seed': 42,
        'max_grad_norm': 1.0,
        'adam_epsilon': 1e-8,
        'warmup_ratio': 0.1
    }
    
    # æ•°æ®é…ç½®
    data_config = {
        'train_file': 'complete_training_data.json',
        'eval_file': 'complete_training_data.json',  # æš‚æ—¶ç”¨åŒä¸€æ–‡ä»¶
        'max_seq_length': 1024,  # ä¸æ¨¡å‹ä¸€è‡´
        'overwrite_cache': False,
        'pad_to_max_length': True,
        'return_overflowing_tokens': False,
        'return_offsets_mapping': False,
        'return_length': False
    }
    
    # å®‰å…¨é…ç½®
    safety_config = {
        'safety_threshold': 0.7,
        'human_reception_threshold': 0.6,
        'language_complexity_threshold': 0.8,
        'enable_safety_monitoring': True,
        'safety_check_interval': 100
    }
    
    # ä¼˜åŒ–é…ç½®
    optimization_config = {
        'use_amp': True,
        'use_apex': False,
        'fp16': True,
        'fp16_opt_level': 'O1',
        'use_distributed': False,
        'num_gpus': 1,
        'gradient_checkpointing': True,
        'save_total_limit': 3
    }
    
    # ç›‘æ§é…ç½®
    monitoring_config = {
        'use_wandb': False,
        'use_tensorboard': True,
        'logging_steps': 100,
        'eval_strategy': 'steps',
        'save_strategy': 'steps',
        'load_best_model_at_end': True,
        'metric_for_best_model': 'eval_loss'
    }
    
    # è§£æˆ‘åè®®è®­ç»ƒé…ç½®
    jiewo_training_config = {
        'jiewo_state_weight': 1.0,
        'ethic_scores_weight': 0.5,
        'safety_weight': 0.3,
        'cognitive_weight': 0.2,
        'enable_jiewo_loss': True,
        'enable_ethic_loss': True,
        'enable_safety_loss': True
    }
    
    # è‡ªæˆ‘è¿­ä»£é…ç½®
    iteration_config = {
        'iteration_interval': 1000,  # æ¯1000æ­¥æ‰§è¡Œä¸€æ¬¡è‡ªæˆ‘è¿­ä»£
        'max_iterations_per_training': 10,
        'improvement_threshold': 0.1,
        'confidence_threshold': 0.7,
        'enable_adaptive_iteration': True,
        'enable_self_iteration': True
    }

def create_training_config():
    """åˆ›å»ºè®­ç»ƒé…ç½®"""
    config = TrainingConfig()
    
    # åˆå¹¶æ‰€æœ‰é…ç½®
    full_config = {
        'model': config.model_config,
        'training': config.training_config,
        'data': config.data_config,
        'safety': config.safety_config,
        'optimization': config.optimization_config,
        'monitoring': config.monitoring_config,
        'jiewo_training': config.jiewo_training_config,
        'iteration': config.iteration_config
    }
    
    # ä¿å­˜é…ç½®
    with open('training_config.json', 'w', encoding='utf-8') as f:
        json.dump(full_config, f, ensure_ascii=False, indent=2)
    
    print("âœ… è®­ç»ƒé…ç½®å·²ä¿å­˜åˆ°: training_config.json")
    
    return full_config

def print_training_summary(config: Dict[str, Any]):
    """æ‰“å°è®­ç»ƒæ‘˜è¦"""
    print("\nğŸ“‹ è®­ç»ƒé…ç½®æ‘˜è¦:")
    print("=" * 60)
    
    print("ğŸ”§ æ¨¡å‹é…ç½®:")
    model = config['model']
    print(f"  è¯æ±‡è¡¨å¤§å°: {model['vocab_size']:,}")
    print(f"  éšè—å±‚å¤§å°: {model['hidden_size']}")
    print(f"  å±‚æ•°: {model['num_layers']}")
    print(f"  æ³¨æ„åŠ›å¤´æ•°: {model['num_heads']}")
    print(f"  æœ€å¤§åºåˆ—é•¿åº¦: {model['max_seq_length']}")
    
    print("\nğŸš€ V4.0åŠŸèƒ½:")
    model = config['model']
    print(f"  Clock(Ï„)æ—¶åºè§¦å‘å™¨: {'âœ…' if model['enable_clock_trigger'] else 'âŒ'}")
    print(f"  è¡¨è¾¾è£å†³å™¨: {'âœ…' if model['enable_expression_arbitrator'] else 'âŒ'}")
    print(f"  è®¤çŸ¥ç–«è‹—æœºåˆ¶: {'âœ…' if model['enable_cognitive_vaccine'] else 'âŒ'}")
    print(f"  è‡ªæˆ‘è¿­ä»£å¼•æ“: {'âœ…' if model['enable_self_iteration'] else 'âŒ'}")
    print(f"  ä¸»åŠ¨å­¦ä¹ å¼•æ“: {'âœ…' if model['enable_active_learning'] else 'âŒ'}")
    
    print("\nğŸ“š è®­ç»ƒé…ç½®:")
    training = config['training']
    print(f"  æ‰¹æ¬¡å¤§å°: {training['batch_size']}")
    print(f"  å­¦ä¹ ç‡: {training['learning_rate']}")
    print(f"  æœ€å¤§æ­¥æ•°: {training['max_steps']:,}")
    print(f"  ä¿å­˜é—´éš”: {training['save_steps']}")
    print(f"  è¯„ä¼°é—´éš”: {training['eval_steps']}")
    
    print("\nğŸ›¡ï¸ å®‰å…¨é…ç½®:")
    safety = config['safety']
    print(f"  å®‰å…¨é˜ˆå€¼: {safety['safety_threshold']}")
    print(f"  äººç±»æ¥æ”¶é˜ˆå€¼: {safety['human_reception_threshold']}")
    print(f"  è¯­è¨€å¤æ‚åº¦é˜ˆå€¼: {safety['language_complexity_threshold']}")
    
    print("\nâš¡ ä¼˜åŒ–é…ç½®:")
    opt = config['optimization']
    print(f"  æ··åˆç²¾åº¦è®­ç»ƒ: {'âœ…' if opt['use_amp'] else 'âŒ'}")
    print(f"  FP16: {'âœ…' if opt['fp16'] else 'âŒ'}")
    print(f"  æ¢¯åº¦æ£€æŸ¥ç‚¹: {'âœ…' if opt['gradient_checkpointing'] else 'âŒ'}")
    
    print("\nğŸ”„ è‡ªæˆ‘è¿­ä»£é…ç½®:")
    iteration = config['iteration']
    print(f"  è¿­ä»£é—´éš”: {iteration['iteration_interval']} æ­¥")
    print(f"  æœ€å¤§è¿­ä»£æ¬¡æ•°: {iteration['max_iterations_per_training']}")
    print(f"  æ”¹è¿›é˜ˆå€¼: {iteration['improvement_threshold']}")
    print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: {iteration['confidence_threshold']}")
    
    print("=" * 60)

if __name__ == "__main__":
    config = create_training_config()
    print_training_summary(config) 