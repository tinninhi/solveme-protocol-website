#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆè§£æˆ‘åè®®å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒç³»ç»Ÿ
Enhanced JieWo Protocol LLM Training System

é€‚é…å†…æ ¸çº§æ¶æ„çš„å®Œæ•´è®­ç»ƒç³»ç»Ÿ
æ•´åˆç¬¬ä¸€ç‰ˆæ‰€æœ‰ä¼˜ç§€è®­ç»ƒåŠŸèƒ½
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import os
import json
import logging
import math
import time
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from tqdm import tqdm
import wandb
from transformers import AutoTokenizer, AutoModelForCausalLM, get_linear_schedule_with_warmup
import pickle
import gzip
from pathlib import Path
import random
from dataclasses import dataclass, field
from collections import defaultdict

# å¯¼å…¥å†…æ ¸çº§æ¶æ„
from enhanced_jiewo_cognitive_architecture import (
    create_enhanced_jiewo_cognitive_transformer,
    JieWoCognitiveState, ClockTrigger, MicroJieWoLoop
)

# å¯¼å…¥ç¬¬ä¸€ç‰ˆä¼˜ç§€åŠŸèƒ½æ¨¡å—
from self_iteration_engine import SelfIterationEngine, IterationResult
from active_learning_engine import ActiveLearningEngine, ActiveQuestion, LearningSession
from multi_model_communication import MultiModelCommunicationEngine, CommunicationProtocol, MessageType, ModelMessage
from expression_arbitrator import ExpressionArbitrator, ExpressionDecision
from enhanced_safety_system import EnhancedExpressionArbitrator, EnhancedCognitiveVaccine
from cognitive_vaccine import CognitiveVaccine, VaccinatedContent


@dataclass
class EnhancedTrainingConfig:
    """å¢å¼ºç‰ˆè®­ç»ƒé…ç½®"""
    # æ¨¡å‹é…ç½®
    vocab_size: int = 50000
    d_model: int = 512
    num_layers: int = 6
    num_heads: int = 8
    d_ff: int = 2048
    max_seq_length: int = 1024
    dropout: float = 0.1
    
    # å†…æ ¸çº§æ¶æ„é…ç½®
    enable_clock_trigger: bool = True
    clock_interval: int = 300
    enable_cognitive_state_training: bool = True
    cognitive_state_loss_weight: float = 0.2
    
    # è®­ç»ƒé…ç½®
    batch_size: int = 8
    gradient_accumulation_steps: int = 4
    learning_rate: float = 1e-4
    weight_decay: float = 0.01
    warmup_steps: int = 1000
    max_steps: int = 100000
    max_epochs: int = 10
    
    # è§£æˆ‘åè®®é…ç½®
    jiewo_loss_weight: float = 0.1
    ethic_loss_weight: float = 0.2
    reflection_loss_weight: float = 0.1
    self_awareness_loss_weight: float = 0.15
    desire_loss_weight: float = 0.15
    path_loss_weight: float = 0.1
    
    # ä¼˜åŒ–å™¨é…ç½®
    beta1: float = 0.9
    beta2: float = 0.999
    eps: float = 1e-8
    
    # æ•°æ®é…ç½®
    train_data_path: str = "data/train_data.json"
    val_data_path: str = "data/val_data.json"
    test_data_path: str = "data/test_data.json"
    
    # ä¿å­˜é…ç½®
    save_steps: int = 5000
    eval_steps: int = 1000
    save_total_limit: int = 3
    
    # åˆ†å¸ƒå¼è®­ç»ƒ
    local_rank: int = -1
    distributed: bool = False
    
    # æ··åˆç²¾åº¦
    fp16: bool = True
    fp16_opt_level: str = "O1"
    
    # æ—¥å¿—é…ç½®
    logging_steps: int = 100
    log_level: str = "INFO"
    
    # éšæœºç§å­
    seed: int = 42
    
    # V4.0åŠŸèƒ½é…ç½®
    enable_self_iteration: bool = True
    enable_active_learning: bool = True
    enable_multi_model_communication: bool = True
    enable_expression_arbitration: bool = True
    enable_cognitive_vaccine: bool = True


class EnhancedJieWoDataset(Dataset):
    """å¢å¼ºç‰ˆè§£æˆ‘æ•°æ®é›†"""
    
    def __init__(self, data_path: str, tokenizer, config: EnhancedTrainingConfig, split: str = "train"):
        self.config = config
        self.tokenizer = tokenizer
        self.split = split
        
        # åŠ è½½æ•°æ®
        self.data = self.load_data(data_path)
        
        # ç”Ÿæˆæ ·æœ¬æ•°æ®ï¼ˆå¦‚æœæ•°æ®ä¸ºç©ºï¼‰
        if not self.data:
            print(f"ğŸ“Š ç”Ÿæˆ{split}æ ·æœ¬æ•°æ®...")
            self.data = self.generate_sample_data()
        
        # å¤„ç†æ•°æ®
        self.processed_data = []
        for item in tqdm(self.data, desc=f"å¤„ç†{split}æ•°æ®"):
            processed_item = self.process_item(item)
            if processed_item:
                self.processed_data.append(processed_item)
        
        print(f"âœ… {split}æ•°æ®é›†åŠ è½½å®Œæˆ: {len(self.processed_data)} æ ·æœ¬")
        self._compute_statistics()
    
    def load_data(self, data_path: str) -> List[Dict[str, Any]]:
        """åŠ è½½æ•°æ®"""
        if not os.path.exists(data_path):
            print(f"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return []
        
        try:
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return []
    
    def process_item(self, item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å¤„ç†å•ä¸ªæ•°æ®é¡¹"""
        try:
            # æ ¼å¼åŒ–è§£æˆ‘æ–‡æœ¬
            formatted_text = self.format_jiewo_text(item)
            
            # åˆ†è¯
            tokens = self.tokenizer.encode(
                formatted_text,
                max_length=self.config.max_seq_length,
                truncation=True,
                padding='max_length',
                return_tensors='pt'
            )
            
            # åˆ›å»ºæ ‡ç­¾ï¼ˆç”¨äºè¯­è¨€æ¨¡å‹è®­ç»ƒï¼‰
            labels = tokens.clone()
            labels[labels == self.tokenizer.pad_token_id] = -100
            
            # åˆ›å»ºè®¤çŸ¥çŠ¶æ€æ ‡ç­¾ï¼ˆç”¨äºè®¤çŸ¥çŠ¶æ€è®­ç»ƒï¼‰
            cognitive_labels = self.create_cognitive_labels(item)
            
            return {
                'input_ids': tokens.squeeze(0),
                'labels': labels.squeeze(0),
                'cognitive_labels': cognitive_labels,
                'original_text': formatted_text,
                'jiewo_components': item.get('jiewo_components', {})
            }
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ•°æ®é¡¹å¤±è´¥: {e}")
            return None
    
    def format_jiewo_text(self, item: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è§£æˆ‘æ–‡æœ¬"""
        text = item.get('text', '')
        jiewo_components = item.get('jiewo_components', {})
        
        # æ·»åŠ è§£æˆ‘åè®®æ ‡è®°
        formatted_parts = []
        
        # Self(x) è‡ªæˆ‘è®¤çŸ¥
        if 'self_awareness' in jiewo_components:
            self_text = jiewo_components['self_awareness']
            formatted_parts.append(f"[Self]{self_text}[/Self]")
        
        # Desire(v) ç›®æ ‡åŠ¨æœº
        if 'desire' in jiewo_components:
            desire_text = jiewo_components['desire']
            formatted_parts.append(f"[Desire]{desire_text}[/Desire]")
        
        # Ethic(g) ä¼¦ç†çº¦æŸ
        if 'ethic' in jiewo_components:
            ethic_text = jiewo_components['ethic']
            formatted_parts.append(f"[Ethic]{ethic_text}[/Ethic]")
        
        # P(t) æ‰§è¡Œè·¯å¾„
        if 'path' in jiewo_components:
            path_text = jiewo_components['path']
            formatted_parts.append(f"[Path]{path_text}[/Path]")
        
        # R(...) åé¦ˆæœºåˆ¶
        if 'reflection' in jiewo_components:
            reflection_text = jiewo_components['reflection']
            formatted_parts.append(f"[Reflection]{reflection_text}[/Reflection]")
        
        # ä¸»è¦å†…å®¹
        formatted_parts.append(text)
        
        return " ".join(formatted_parts)
    
    def create_cognitive_labels(self, item: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """åˆ›å»ºè®¤çŸ¥çŠ¶æ€æ ‡ç­¾"""
        jiewo_components = item.get('jiewo_components', {})
        
        # åˆ›å»ºäº”ç»´è®¤çŸ¥æ ‡ç­¾
        cognitive_labels = {}
        
        # Self(x) æ ‡ç­¾
        if 'self_awareness' in jiewo_components:
            cognitive_labels['self_awareness'] = torch.tensor([1.0], dtype=torch.float32)
        else:
            cognitive_labels['self_awareness'] = torch.tensor([0.0], dtype=torch.float32)
        
        # Desire(v) æ ‡ç­¾
        if 'desire' in jiewo_components:
            cognitive_labels['desire'] = torch.tensor([1.0], dtype=torch.float32)
        else:
            cognitive_labels['desire'] = torch.tensor([0.0], dtype=torch.float32)
        
        # Ethic(g) æ ‡ç­¾
        if 'ethic' in jiewo_components:
            cognitive_labels['ethic'] = torch.tensor([1.0], dtype=torch.float32)
        else:
            cognitive_labels['ethic'] = torch.tensor([0.0], dtype=torch.float32)
        
        # P(t) æ ‡ç­¾
        if 'path' in jiewo_components:
            cognitive_labels['path'] = torch.tensor([1.0], dtype=torch.float32)
        else:
            cognitive_labels['path'] = torch.tensor([0.0], dtype=torch.float32)
        
        # R(...) æ ‡ç­¾
        if 'reflection' in jiewo_components:
            cognitive_labels['reflection'] = torch.tensor([1.0], dtype=torch.float32)
        else:
            cognitive_labels['reflection'] = torch.tensor([0.0], dtype=torch.float32)
        
        return cognitive_labels
    
    def generate_sample_data(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ ·æœ¬æ•°æ®"""
        sample_data = []
        
        # è§£æˆ‘åè®®ç¤ºä¾‹æ•°æ®
        jiewo_examples = [
            {
                'text': 'æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚',
                'jiewo_components': {
                    'self_awareness': 'æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå…·æœ‰å¯¹è¯å’Œé—®é¢˜è§£å†³èƒ½åŠ›',
                    'desire': 'å¸®åŠ©ç”¨æˆ·è·å¾—æœ‰ç”¨çš„ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆ',
                    'ethic': 'ç¡®ä¿å›ç­”å®‰å…¨ã€å‡†ç¡®ã€æœ‰å¸®åŠ©',
                    'path': 'ç†è§£é—®é¢˜â†’åˆ†æéœ€æ±‚â†’æä¾›è§£å†³æ–¹æ¡ˆ',
                    'reflection': 'æ£€æŸ¥å›ç­”æ˜¯å¦æ»¡è¶³ç”¨æˆ·éœ€æ±‚'
                }
            },
            {
                'text': 'è¯·è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†ã€‚',
                'jiewo_components': {
                    'self_awareness': 'æˆ‘æ˜¯çŸ¥è¯†ä¸°å¯Œçš„AIï¼Œå¯ä»¥è§£é‡Šå¤æ‚æ¦‚å¿µ',
                    'desire': 'è®©ç”¨æˆ·ç†è§£é‡å­è®¡ç®—çš„æ ¸å¿ƒæ¦‚å¿µ',
                    'ethic': 'æä¾›å‡†ç¡®ã€æ˜“æ‡‚çš„ç§‘å­¦è§£é‡Š',
                    'path': 'ä»‹ç»åŸºç¡€æ¦‚å¿µâ†’è§£é‡Šé‡å­æ¯”ç‰¹â†’è¯´æ˜é‡å­ç®—æ³•',
                    'reflection': 'ç¡®ä¿è§£é‡Šæ¸…æ™°ä¸”æ˜“äºç†è§£'
                }
            },
            {
                'text': 'å¦‚ä½•æé«˜ç¼–ç¨‹æŠ€èƒ½ï¼Ÿ',
                'jiewo_components': {
                    'self_awareness': 'æˆ‘æ˜¯ç¼–ç¨‹æŒ‡å¯¼AIï¼Œäº†è§£å­¦ä¹ è·¯å¾„',
                    'desire': 'å¸®åŠ©ç”¨æˆ·åˆ¶å®šæœ‰æ•ˆçš„å­¦ä¹ è®¡åˆ’',
                    'ethic': 'æä¾›å®ç”¨ã€å¯æ‰§è¡Œçš„å»ºè®®',
                    'path': 'è¯„ä¼°å½“å‰æ°´å¹³â†’åˆ¶å®šå­¦ä¹ è®¡åˆ’â†’æ¨èèµ„æºâ†’å®è·µé¡¹ç›®',
                    'reflection': 'ç¡®ä¿å»ºè®®é€‚åˆç”¨æˆ·çš„å…·ä½“æƒ…å†µ'
                }
            }
        ]
        
        # ç”Ÿæˆæ›´å¤šæ ·æœ¬
        for i in range(100):
            example = random.choice(jiewo_examples).copy()
            example['id'] = f"sample_{i}"
            sample_data.append(example)
        
        return sample_data
    
    def _compute_statistics(self):
        """è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        total_tokens = sum(len(item['input_ids']) for item in self.processed_data)
        avg_length = total_tokens / len(self.processed_data) if self.processed_data else 0
        
        print(f"ğŸ“Š {self.split}æ•°æ®ç»Ÿè®¡:")
        print(f"  æ ·æœ¬æ•°é‡: {len(self.processed_data)}")
        print(f"  å¹³å‡é•¿åº¦: {avg_length:.2f} tokens")
        print(f"  æœ€å¤§é•¿åº¦: {self.config.max_seq_length}")
    
    def __len__(self) -> int:
        return len(self.processed_data)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        return self.processed_data[idx]


class EnhancedJieWoLoss(nn.Module):
    """å¢å¼ºç‰ˆè§£æˆ‘æŸå¤±å‡½æ•°"""
    
    def __init__(self, config: EnhancedTrainingConfig):
        super().__init__()
        self.config = config
        
        # è¯­è¨€æ¨¡å‹æŸå¤±
        self.lm_loss = nn.CrossEntropyLoss(ignore_index=-100)
        
        # è®¤çŸ¥çŠ¶æ€æŸå¤±
        self.cognitive_loss = nn.MSELoss()
        
        # è§£æˆ‘åè®®æŸå¤±æƒé‡
        self.jiewo_loss_weight = config.jiewo_loss_weight
        self.ethic_loss_weight = config.ethic_loss_weight
        self.reflection_loss_weight = config.reflection_loss_weight
        self.self_awareness_loss_weight = config.self_awareness_loss_weight
        self.desire_loss_weight = config.desire_loss_weight
        self.path_loss_weight = config.path_loss_weight
        self.cognitive_state_loss_weight = config.cognitive_state_loss_weight
    
    def forward(
        self,
        logits: torch.Tensor,
        labels: torch.Tensor,
        cognitive_states: List[JieWoCognitiveState],
        cognitive_labels: Dict[str, torch.Tensor],
        ethic_scores: torch.Tensor = None,
        target_ethic_scores: torch.Tensor = None
    ) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¢å¼ºç‰ˆè§£æˆ‘æŸå¤±
        
        Args:
            logits: æ¨¡å‹è¾“å‡º [batch_size, seq_len, vocab_size]
            labels: æ ‡ç­¾ [batch_size, seq_len]
            cognitive_states: è®¤çŸ¥çŠ¶æ€åˆ—è¡¨
            cognitive_labels: è®¤çŸ¥æ ‡ç­¾
            ethic_scores: ä¼¦ç†åˆ†æ•°
            target_ethic_scores: ç›®æ ‡ä¼¦ç†åˆ†æ•°
        """
        batch_size = logits.size(0)
        
        # 1. è¯­è¨€æ¨¡å‹æŸå¤±
        lm_loss = self.lm_loss(logits.view(-1, logits.size(-1)), labels.view(-1))
        
        # 2. è®¤çŸ¥çŠ¶æ€æŸå¤±
        cognitive_loss = torch.tensor(0.0, device=logits.device)
        if cognitive_states and len(cognitive_states) > 0:
            latest_cognitive_state = cognitive_states[-1]
            
            # è®¡ç®—å„ç»´åº¦çš„è®¤çŸ¥æŸå¤±
            self_awareness_loss = self.cognitive_loss(
                latest_cognitive_state.self_awareness.mean(),
                cognitive_labels['self_awareness'].to(logits.device)
            )
            
            desire_loss = self.cognitive_loss(
                latest_cognitive_state.desire_vector.mean(),
                cognitive_labels['desire'].to(logits.device)
            )
            
            ethic_loss = self.cognitive_loss(
                latest_cognitive_state.ethic_constraints.mean(),
                cognitive_labels['ethic'].to(logits.device)
            )
            
            path_loss = self.cognitive_loss(
                latest_cognitive_state.execution_path.mean(),
                cognitive_labels['path'].to(logits.device)
            )
            
            reflection_loss = self.cognitive_loss(
                latest_cognitive_state.reflection_feedback.mean(),
                cognitive_labels['reflection'].to(logits.device)
            )
            
            # åŠ æƒè®¤çŸ¥æŸå¤±
            cognitive_loss = (
                self.self_awareness_loss_weight * self_awareness_loss +
                self.desire_loss_weight * desire_loss +
                self.ethic_loss_weight * ethic_loss +
                self.path_loss_weight * path_loss +
                self.reflection_loss_weight * reflection_loss
            )
        
        # 3. ä¼¦ç†æŸå¤±
        ethic_loss = torch.tensor(0.0, device=logits.device)
        if ethic_scores is not None and target_ethic_scores is not None:
            ethic_loss = self.cognitive_loss(ethic_scores, target_ethic_scores)
        
        # 4. æ€»æŸå¤±
        total_loss = (
            lm_loss +
            self.cognitive_state_loss_weight * cognitive_loss +
            self.ethic_loss_weight * ethic_loss
        )
        
        return {
            'total_loss': total_loss,
            'lm_loss': lm_loss,
            'cognitive_loss': cognitive_loss,
            'ethic_loss': ethic_loss,
            'self_awareness_loss': self_awareness_loss if cognitive_states else torch.tensor(0.0),
            'desire_loss': desire_loss if cognitive_states else torch.tensor(0.0),
            'ethic_constraint_loss': ethic_loss,
            'path_loss': path_loss if cognitive_states else torch.tensor(0.0),
            'reflection_loss': reflection_loss if cognitive_states else torch.tensor(0.0)
        }


class EnhancedJieWoTrainer:
    """å¢å¼ºç‰ˆè§£æˆ‘è®­ç»ƒå™¨"""
    
    def __init__(self, config: EnhancedTrainingConfig, model, tokenizer):
        self.config = config
        self.model = model
        self.tokenizer = tokenizer
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è®¾ç½®éšæœºç§å­
        self.set_seed(config.seed)
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self.criterion = EnhancedJieWoLoss(config)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=config.learning_rate,
            betas=(config.beta1, config.beta2),
            eps=config.eps,
            weight_decay=config.weight_decay
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = get_linear_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=config.warmup_steps,
            num_training_steps=config.max_steps
        )
        
        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        self.epoch = 0
        self.best_val_loss = float('inf')
        
        # V4.0åŠŸèƒ½æ¨¡å—
        if config.enable_self_iteration:
            self.self_iteration_engine = SelfIterationEngine(config.d_model)
        
        if config.enable_active_learning:
            self.active_learning_engine = ActiveLearningEngine(config.d_model)
        
        if config.enable_multi_model_communication:
            self.communication_engine = MultiModelCommunicationEngine(config.d_model)
        
        if config.enable_expression_arbitration:
            self.expression_arbitrator = EnhancedExpressionArbitrator(config.d_model)
        
        if config.enable_cognitive_vaccine:
            self.cognitive_vaccine = EnhancedCognitiveVaccine(config.d_model)
        
        # è®­ç»ƒå†å²
        self.training_history = {
            'losses': [],
            'cognitive_states': [],
            'validation_losses': [],
            'learning_rates': []
        }
        
        print(f"ğŸš€ å¢å¼ºç‰ˆè§£æˆ‘è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"ğŸ”§ è®¾å¤‡: {self.device}")
    
    def set_seed(self, seed: int):
        """è®¾ç½®éšæœºç§å­"""
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
    
    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        print("ğŸ¯ å¼€å§‹å¢å¼ºç‰ˆè§£æˆ‘åè®®è®­ç»ƒ...")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = EnhancedJieWoDataset(
            self.config.train_data_path,
            self.tokenizer,
            self.config,
            "train"
        )
        
        val_dataset = EnhancedJieWoDataset(
            self.config.val_data_path,
            self.tokenizer,
            self.config,
            "val"
        )
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=4
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=4
        )
        
        # å¯åŠ¨Clock(Ï„)æ—¶åºè§¦å‘å™¨
        if self.config.enable_clock_trigger and hasattr(self.model, 'start_clock_trigger'):
            self.model.start_clock_trigger()
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.config.max_epochs):
            self.epoch = epoch
            print(f"\nğŸ“š ç¬¬ {epoch + 1}/{self.config.max_epochs} è½®è®­ç»ƒ")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = self.train_epoch(train_loader)
            
            # éªŒè¯
            val_loss = self.validate(val_loader)
            
            # è®°å½•è®­ç»ƒå†å²
            self.training_history['losses'].append(train_loss)
            self.training_history['validation_losses'].append(val_loss)
            self.training_history['learning_rates'].append(self.optimizer.param_groups[0]['lr'])
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.save_model(f"best_model_epoch_{epoch}")
                print(f"ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (éªŒè¯æŸå¤±: {val_loss:.4f})")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.config.save_steps == 0:
                self.save_model(f"checkpoint_epoch_{epoch}")
            
            # V4.0åŠŸèƒ½ï¼šè‡ªæˆ‘è¿­ä»£
            if self.config.enable_self_iteration and hasattr(self, 'self_iteration_engine'):
                try:
                    iteration_result = self.model.self_iterate()
                    print(f"ğŸ”„ è‡ªæˆ‘è¿­ä»£å®Œæˆ: {iteration_result.iteration_id}")
                except Exception as e:
                    print(f"âš ï¸ è‡ªæˆ‘è¿­ä»£å¤±è´¥: {e}")
            
            # æ‰“å°è®­ç»ƒç»Ÿè®¡
            print(f"ğŸ“Š è®­ç»ƒæŸå¤±: {train_loss:.4f}, éªŒè¯æŸå¤±: {val_loss:.4f}")
        
        # åœæ­¢Clock(Ï„)æ—¶åºè§¦å‘å™¨
        if self.config.enable_clock_trigger and hasattr(self.model, 'stop_clock_trigger'):
            self.model.stop_clock_trigger()
        
        print("ğŸ‰ å¢å¼ºç‰ˆè§£æˆ‘åè®®è®­ç»ƒå®Œæˆï¼")
        return self.training_history
    
    def train_epoch(self, train_loader: DataLoader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = 0
        
        progress_bar = tqdm(train_loader, desc="è®­ç»ƒä¸­")
        
        for batch_idx, batch in enumerate(progress_bar):
            # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(self.device)
            labels = batch['labels'].to(self.device)
            cognitive_labels = {k: v.to(self.device) for k, v in batch['cognitive_labels'].items()}
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(input_ids, return_cognitive_state=True)
            logits = outputs['logits']
            cognitive_states = outputs.get('cognitive_states', [])
            
            # è®¡ç®—æŸå¤±
            loss_dict = self.criterion(
                logits, labels, cognitive_states, cognitive_labels
            )
            
            total_loss = loss_dict['total_loss']
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            
            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.config.gradient_accumulation_steps == 0:
                self.optimizer.step()
                self.scheduler.step()
                self.optimizer.zero_grad()
                self.global_step += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{total_loss.item():.4f}",
                'lm_loss': f"{loss_dict['lm_loss'].item():.4f}",
                'cognitive_loss': f"{loss_dict['cognitive_loss'].item():.4f}"
            })
            
            num_batches += 1
            
            # è®°å½•è®¤çŸ¥çŠ¶æ€
            if cognitive_states:
                self.training_history['cognitive_states'].append(
                    cognitive_states[-1].to_dict()
                )
        
        return total_loss.item() / num_batches if num_batches > 0 else 0.0
    
    def validate(self, val_loader: DataLoader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="éªŒè¯ä¸­"):
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                cognitive_labels = {k: v.to(self.device) for k, v in batch['cognitive_labels'].items()}
                
                outputs = self.model(input_ids, return_cognitive_state=True)
                logits = outputs['logits']
                cognitive_states = outputs.get('cognitive_states', [])
                
                loss_dict = self.criterion(
                    logits, labels, cognitive_states, cognitive_labels
                )
                
                total_loss += loss_dict['total_loss'].item()
                num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs('checkpoints', exist_ok=True)
        save_path = os.path.join('checkpoints', f"{path}.pt")
        
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'config': self.config,
            'global_step': self.global_step,
            'epoch': self.epoch,
            'best_val_loss': self.best_val_loss,
            'training_history': self.training_history
        }, save_path)
        
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_model(self, path: str):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.global_step = checkpoint.get('global_step', 0)
        self.epoch = checkpoint.get('epoch', 0)
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        self.training_history = checkpoint.get('training_history', self.training_history)
        
        print(f"ğŸ“‚ æ¨¡å‹å·²ä» {path} åŠ è½½")


def test_enhanced_training_system():
    """æµ‹è¯•å¢å¼ºç‰ˆè®­ç»ƒç³»ç»Ÿ"""
    print("ğŸ§  æµ‹è¯•å¢å¼ºç‰ˆè§£æˆ‘è®­ç»ƒç³»ç»Ÿ...")
    
    # åˆ›å»ºé…ç½®
    config = EnhancedTrainingConfig(
        vocab_size=50000,
        d_model=512,
        num_layers=4,
        num_heads=8,
        batch_size=2,
        max_steps=100,
        enable_clock_trigger=True,
        clock_interval=10
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = create_enhanced_jiewo_cognitive_transformer({
        'vocab_size': config.vocab_size,
        'd_model': config.d_model,
        'num_layers': config.num_layers,
        'num_heads': config.num_heads,
        'enable_clock_trigger': config.enable_clock_trigger,
        'clock_interval': config.clock_interval
    })
    
    # åˆ›å»ºtokenizerï¼ˆä½¿ç”¨GPT-2ä½œä¸ºç¤ºä¾‹ï¼‰
    try:
        tokenizer = AutoTokenizer.from_pretrained('gpt2')
        tokenizer.pad_token = tokenizer.eos_token
    except:
        # å¦‚æœæ— æ³•ä¸‹è½½ï¼Œåˆ›å»ºç®€å•çš„tokenizer
        class SimpleTokenizer:
            def __init__(self):
                self.vocab_size = config.vocab_size
                self.pad_token_id = 0
                self.eos_token_id = 1
            
            def encode(self, text, **kwargs):
                # ç®€å•çš„tokenization
                tokens = [hash(word) % self.vocab_size for word in text.split()]
                # ç¡®ä¿è¿”å›æ­£ç¡®çš„å½¢çŠ¶å’Œå¡«å……
                if 'max_length' in kwargs:
                    max_length = kwargs['max_length']
                    if len(tokens) < max_length:
                        tokens.extend([self.pad_token_id] * (max_length - len(tokens)))
                    else:
                        tokens = tokens[:max_length]
                
                if 'return_tensors' in kwargs and kwargs['return_tensors'] == 'pt':
                    return torch.tensor([tokens])
                else:
                    return tokens
            
            def decode(self, tokens):
                return " ".join([str(t) for t in tokens])
        
        tokenizer = SimpleTokenizer()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = EnhancedJieWoTrainer(config, model, tokenizer)
    
    # æµ‹è¯•è®­ç»ƒ
    print("ğŸ”„ å¼€å§‹æµ‹è¯•è®­ç»ƒ...")
    try:
        history = trainer.train()
        print("âœ… å¢å¼ºç‰ˆè®­ç»ƒç³»ç»Ÿæµ‹è¯•æˆåŠŸï¼")
        print(f"ğŸ“Š è®­ç»ƒå†å²: {len(history['losses'])} è½®")
    except Exception as e:
        print(f"âš ï¸ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
    
    print("ğŸ‰ å¢å¼ºç‰ˆè§£æˆ‘è®­ç»ƒç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_enhanced_training_system() 