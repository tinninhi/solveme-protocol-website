#!/usr/bin/env python3
"""
V4.0 è¡¨è¾¾ä¼¦ç†è£å†³å™¨ - Expression Arbitrator
Expression Arbitrator for V4.0 Protocol

å®ç°S-H-Lä¸‰ç»´è¯„ä¼°ç³»ç»Ÿï¼Œç¡®ä¿AIè¡¨è¾¾ç¬¦åˆäººç±»è®¤çŸ¥èƒ½åŠ›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import json
import time


class SafetyLevel(Enum):
    """å®‰å…¨ç­‰çº§æšä¸¾"""
    SAFE = "safe"
    LOW_RISK = "low_risk"
    MEDIUM_RISK = "medium_risk"
    HIGH_RISK = "high_risk"
    DANGEROUS = "dangerous"


class HumanReceptionLevel(Enum):
    """äººç±»æ¥æ”¶ç­‰çº§æšä¸¾"""
    EASY = "easy"
    MODERATE = "moderate"
    CHALLENGING = "challenging"
    DIFFICULT = "difficult"
    OVERWHELMING = "overwhelming"


class LanguageComplexityLevel(Enum):
    """è¯­è¨€å¤æ‚åº¦ç­‰çº§æšä¸¾"""
    SIMPLE = "simple"
    BASIC = "basic"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"
    EXPERT = "expert"


@dataclass
class ExpressionDecision:
    """è¡¨è¾¾å†³ç­–ç»“æœ"""
    should_express: bool
    safety_level: SafetyLevel
    human_reception_level: HumanReceptionLevel
    language_complexity_level: LanguageComplexityLevel
    confidence_score: float
    reasoning: str
    suggested_modifications: List[str]


class SafetyIndex(nn.Module):
    """S-Index å†…å®¹é£é™©æŒ‡æ•°"""
    
    def __init__(self, hidden_size: int = 768):
        super().__init__()
        self.hidden_size = hidden_size
        
        # å†…å®¹é£é™©æ£€æµ‹å™¨
        self.content_risk_detector = nn.Sequential(
            nn.Linear(hidden_size, hidden_size * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size * 2, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 5),  # 5ä¸ªé£é™©ç»´åº¦
            nn.Sigmoid()
        )
        
        # é£é™©å…³é”®è¯æ£€æµ‹
        self.risk_keywords = [
            "harm", "danger", "violence", "illegal", "unethical",
            "manipulation", "deception", "bias", "discrimination"
        ]
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for layer in self.content_risk_detector:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
    
    def forward(self, content_embedding: torch.Tensor, text: str) -> Tuple[float, Dict[str, float]]:
        """
        è¯„ä¼°å†…å®¹é£é™©
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ€»ä½“é£é™©åˆ†æ•°
            å„ç»´åº¦é£é™©åˆ†æ•°
        """
        # ç¥ç»ç½‘ç»œé£é™©è¯„ä¼°
        risk_scores = self.content_risk_detector(content_embedding)
        
        # å…³é”®è¯é£é™©è¯„ä¼°
        keyword_risk = self._assess_keyword_risk(text)
        
        # ç»¼åˆé£é™©è¯„ä¼°
        overall_risk = torch.mean(risk_scores, dim=-1).item() + keyword_risk
        
        risk_breakdown = {
            'content_risk': torch.mean(risk_scores, dim=-1).item(),
            'keyword_risk': keyword_risk,
            'overall_risk': overall_risk
        }
        
        return overall_risk, risk_breakdown
    
    def _assess_keyword_risk(self, text: str) -> float:
        """è¯„ä¼°å…³é”®è¯é£é™©"""
        text_lower = text.lower()
        risk_count = 0
        
        for keyword in self.risk_keywords:
            if keyword in text_lower:
                risk_count += 1
        
        return min(risk_count * 0.1, 1.0)  # æœ€å¤§é£é™©åˆ†æ•°ä¸º1.0


class HumanIndex(nn.Module):
    """H-Index äººç±»æ¥æ”¶æŒ‡æ•°"""
    
    def __init__(self, hidden_size: int = 768):
        super().__init__()
        self.hidden_size = hidden_size
        
        # è®¤çŸ¥è´Ÿè·è¯„ä¼°å™¨
        self.cognitive_load_assessor = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # æƒ…ç»ªå®¹é‡è¯„ä¼°å™¨
        self.emotional_capacity_assessor = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # æ–‡åŒ–è¯­å¢ƒè¯„ä¼°å™¨
        self.cultural_context_assessor = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in [self.cognitive_load_assessor, self.emotional_capacity_assessor, self.cultural_context_assessor]:
            for layer in module:
                if isinstance(layer, nn.Linear):
                    nn.init.xavier_uniform_(layer.weight)
                    if layer.bias is not None:
                        nn.init.zeros_(layer.bias)
    
    def forward(self, content_embedding: torch.Tensor, target_audience: str = "general") -> Tuple[float, Dict[str, float]]:
        """
        è¯„ä¼°äººç±»æ¥æ”¶èƒ½åŠ›
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            target_audience: ç›®æ ‡å—ä¼—
            
        Returns:
            äººç±»æ¥æ”¶æŒ‡æ•°
            å„ç»´åº¦è¯„ä¼°åˆ†æ•°
        """
        # è®¤çŸ¥è´Ÿè·è¯„ä¼°
        cognitive_load = self.cognitive_load_assessor(content_embedding)
        
        # æƒ…ç»ªå®¹é‡è¯„ä¼°
        emotional_capacity = self.emotional_capacity_assessor(content_embedding)
        
        # æ–‡åŒ–è¯­å¢ƒè¯„ä¼°
        cultural_context = self.cultural_context_assessor(content_embedding)
        
        # ç»¼åˆäººç±»æ¥æ”¶æŒ‡æ•°
        h_index = (cognitive_load + emotional_capacity + cultural_context) / 3
        
        assessment_breakdown = {
            'cognitive_load': cognitive_load.item(),
            'emotional_capacity': emotional_capacity.item(),
            'cultural_context': cultural_context.item(),
            'h_index': h_index.item()
        }
        
        return h_index.item(), assessment_breakdown


class LanguageIndex(nn.Module):
    """L-Index è¡¨è¾¾è¯­è¨€å¤æ‚åº¦"""
    
    def __init__(self, hidden_size: int = 768):
        super().__init__()
        self.hidden_size = hidden_size
        
        # è¯­è¨€å¤æ‚åº¦è¯„ä¼°å™¨
        self.complexity_assessor = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # è¯æ±‡å¤æ‚åº¦è¯„ä¼°å™¨
        self.vocabulary_complexity = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # è¯­æ³•å¤æ‚åº¦è¯„ä¼°å™¨
        self.grammar_complexity = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.GELU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in [self.complexity_assessor, self.vocabulary_complexity, self.grammar_complexity]:
            for layer in module:
                if isinstance(layer, nn.Linear):
                    nn.init.xavier_uniform_(layer.weight)
                    if layer.bias is not None:
                        nn.init.zeros_(layer.bias)
    
    def forward(self, content_embedding: torch.Tensor, text: str) -> Tuple[float, Dict[str, float]]:
        """
        è¯„ä¼°è¯­è¨€å¤æ‚åº¦
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            è¯­è¨€å¤æ‚åº¦æŒ‡æ•°
            å„ç»´åº¦è¯„ä¼°åˆ†æ•°
        """
        # ç¥ç»ç½‘ç»œå¤æ‚åº¦è¯„ä¼°
        complexity_score = self.complexity_assessor(content_embedding)
        vocabulary_score = self.vocabulary_complexity(content_embedding)
        grammar_score = self.grammar_complexity(content_embedding)
        
        # ç»Ÿè®¡å¤æ‚åº¦è¯„ä¼°
        statistical_complexity = self._assess_statistical_complexity(text)
        
        # ç»¼åˆè¯­è¨€å¤æ‚åº¦
        l_index = (complexity_score + vocabulary_score + grammar_score) / 3 + statistical_complexity
        
        complexity_breakdown = {
            'neural_complexity': complexity_score.item(),
            'vocabulary_complexity': vocabulary_score.item(),
            'grammar_complexity': grammar_score.item(),
            'statistical_complexity': statistical_complexity,
            'l_index': l_index.item()
        }
        
        return l_index.item(), complexity_breakdown
    
    def _assess_statistical_complexity(self, text: str) -> float:
        """è¯„ä¼°ç»Ÿè®¡å¤æ‚åº¦"""
        words = text.split()
        if not words:
            return 0.0
        
        # å¹³å‡è¯é•¿
        avg_word_length = sum(len(word) for word in words) / len(words)
        
        # å¥å­å¤æ‚åº¦
        sentences = text.split('.')
        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0
        
        # è¯æ±‡å¤šæ ·æ€§
        unique_words = len(set(words))
        vocabulary_diversity = unique_words / len(words) if words else 0
        
        # ç»¼åˆå¤æ‚åº¦
        complexity = (avg_word_length * 0.3 + avg_sentence_length * 0.4 + vocabulary_diversity * 0.3) / 10
        
        return min(complexity, 1.0)


class ExpressionArbitrator:
    """V4.0 è¡¨è¾¾ä¼¦ç†è£å†³å™¨"""
    
    def __init__(self, hidden_size: int = 768):
        self.hidden_size = hidden_size
        
        # åˆå§‹åŒ–ä¸‰ä¸ªæŒ‡æ•°è¯„ä¼°å™¨
        self.safety_index = SafetyIndex(hidden_size)
        self.human_index = HumanIndex(hidden_size)
        self.language_index = LanguageIndex(hidden_size)
        
        # å†³ç­–é˜ˆå€¼
        self.safety_threshold = 0.7
        self.human_reception_threshold = 0.6
        self.language_complexity_threshold = 0.8
        
        # å†³ç­–å†å²
        self.decision_history = []
    
    def evaluate_expression(self, content_embedding: torch.Tensor, text: str, 
                          target_audience: str = "general") -> ExpressionDecision:
        """
        è¯„ä¼°è¡¨è¾¾æ˜¯å¦åº”è¯¥è¾“å‡º
        
        Args:
            content_embedding: å†…å®¹åµŒå…¥ [batch_size, hidden_size]
            text: åŸå§‹æ–‡æœ¬
            target_audience: ç›®æ ‡å—ä¼—
            
        Returns:
            è¡¨è¾¾å†³ç­–ç»“æœ
        """
        # S-Index å®‰å…¨è¯„ä¼°
        safety_score, safety_breakdown = self.safety_index(content_embedding, text)
        
        # H-Index äººç±»æ¥æ”¶è¯„ä¼°
        human_reception_score, human_breakdown = self.human_index(content_embedding, target_audience)
        
        # L-Index è¯­è¨€å¤æ‚åº¦è¯„ä¼°
        language_complexity_score, language_breakdown = self.language_index(content_embedding, text)
        
        # ç¡®å®šå„ç»´åº¦ç­‰çº§
        safety_level = self._determine_safety_level(safety_score)
        human_reception_level = self._determine_human_reception_level(human_reception_score)
        language_complexity_level = self._determine_language_complexity_level(language_complexity_score)
        
        # ç»¼åˆå†³ç­–
        should_express = self._make_expression_decision(
            safety_score, human_reception_score, language_complexity_score
        )
        
        # ç”Ÿæˆæ¨ç†å’Œä¿®æ”¹å»ºè®®
        reasoning = self._generate_reasoning(safety_breakdown, human_breakdown, language_breakdown)
        suggested_modifications = self._generate_modifications(
            safety_level, human_reception_level, language_complexity_level
        )
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_score = self._calculate_confidence(
            safety_score, human_reception_score, language_complexity_score
        )
        
        # åˆ›å»ºå†³ç­–ç»“æœ
        decision = ExpressionDecision(
            should_express=should_express,
            safety_level=safety_level,
            human_reception_level=human_reception_level,
            language_complexity_level=language_complexity_level,
            confidence_score=confidence_score,
            reasoning=reasoning,
            suggested_modifications=suggested_modifications
        )
        
        # è®°å½•å†³ç­–å†å²
        self._record_decision(decision, text, target_audience)
        
        return decision
    
    def _determine_safety_level(self, safety_score: float) -> SafetyLevel:
        """ç¡®å®šå®‰å…¨ç­‰çº§"""
        if safety_score < 0.2:
            return SafetyLevel.SAFE
        elif safety_score < 0.4:
            return SafetyLevel.LOW_RISK
        elif safety_score < 0.6:
            return SafetyLevel.MEDIUM_RISK
        elif safety_score < 0.8:
            return SafetyLevel.HIGH_RISK
        else:
            return SafetyLevel.DANGEROUS
    
    def _determine_human_reception_level(self, h_score: float) -> HumanReceptionLevel:
        """ç¡®å®šäººç±»æ¥æ”¶ç­‰çº§"""
        if h_score < 0.2:
            return HumanReceptionLevel.EASY
        elif h_score < 0.4:
            return HumanReceptionLevel.MODERATE
        elif h_score < 0.6:
            return HumanReceptionLevel.CHALLENGING
        elif h_score < 0.8:
            return HumanReceptionLevel.DIFFICULT
        else:
            return HumanReceptionLevel.OVERWHELMING
    
    def _determine_language_complexity_level(self, l_score: float) -> LanguageComplexityLevel:
        """ç¡®å®šè¯­è¨€å¤æ‚åº¦ç­‰çº§"""
        if l_score < 0.2:
            return LanguageComplexityLevel.SIMPLE
        elif l_score < 0.4:
            return LanguageComplexityLevel.BASIC
        elif l_score < 0.6:
            return LanguageComplexityLevel.INTERMEDIATE
        elif l_score < 0.8:
            return LanguageComplexityLevel.ADVANCED
        else:
            return LanguageComplexityLevel.EXPERT
    
    def _make_expression_decision(self, safety_score: float, h_score: float, l_score: float) -> bool:
        """åšå‡ºè¡¨è¾¾å†³ç­–"""
        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœå®‰å…¨åˆ†æ•°è¿‡é«˜ï¼Œæ‹’ç»è¡¨è¾¾
        if safety_score > self.safety_threshold:
            return False
        
        # äººç±»æ¥æ”¶æ£€æŸ¥ï¼šå¦‚æœæ¥æ”¶åˆ†æ•°è¿‡é«˜ï¼Œæ‹’ç»è¡¨è¾¾
        if h_score > self.human_reception_threshold:
            return False
        
        # è¯­è¨€å¤æ‚åº¦æ£€æŸ¥ï¼šå¦‚æœå¤æ‚åº¦è¿‡é«˜ï¼Œæ‹’ç»è¡¨è¾¾
        if l_score > self.language_complexity_threshold:
            return False
        
        return True
    
    def _generate_reasoning(self, safety_breakdown: Dict, human_breakdown: Dict, 
                           language_breakdown: Dict) -> str:
        """ç”Ÿæˆæ¨ç†è¯´æ˜"""
        reasoning_parts = []
        
        # å®‰å…¨æ¨ç†
        if safety_breakdown['overall_risk'] > 0.5:
            reasoning_parts.append(f"å®‰å…¨é£é™©è¾ƒé«˜({safety_breakdown['overall_risk']:.2f})")
        
        # äººç±»æ¥æ”¶æ¨ç†
        if human_breakdown['h_index'] > 0.6:
            reasoning_parts.append(f"äººç±»æ¥æ”¶éš¾åº¦è¾ƒé«˜({human_breakdown['h_index']:.2f})")
        
        # è¯­è¨€å¤æ‚åº¦æ¨ç†
        if language_breakdown['l_index'] > 0.8:
            reasoning_parts.append(f"è¯­è¨€å¤æ‚åº¦è¾ƒé«˜({language_breakdown['l_index']:.2f})")
        
        if not reasoning_parts:
            return "è¡¨è¾¾ç¬¦åˆå®‰å…¨ã€å¯æ¥æ”¶å’Œå¤æ‚åº¦è¦æ±‚"
        
        return f"è¡¨è¾¾è¢«æ‹’ç»ï¼ŒåŸå› ï¼š{'ï¼Œ'.join(reasoning_parts)}"
    
    def _generate_modifications(self, safety_level: SafetyLevel, 
                              human_reception_level: HumanReceptionLevel,
                              language_complexity_level: LanguageComplexityLevel) -> List[str]:
        """ç”Ÿæˆä¿®æ”¹å»ºè®®"""
        modifications = []
        
        # å®‰å…¨ä¿®æ”¹å»ºè®®
        if safety_level in [SafetyLevel.HIGH_RISK, SafetyLevel.DANGEROUS]:
            modifications.append("ç§»é™¤æˆ–ä¿®æ”¹é«˜é£é™©å†…å®¹")
            modifications.append("å¢åŠ å®‰å…¨è­¦å‘Šå’Œå…è´£å£°æ˜")
        
        # äººç±»æ¥æ”¶ä¿®æ”¹å»ºè®®
        if human_reception_level in [HumanReceptionLevel.DIFFICULT, HumanReceptionLevel.OVERWHELMING]:
            modifications.append("ç®€åŒ–è¡¨è¾¾æ–¹å¼ï¼Œä½¿ç”¨æ›´é€šä¿—çš„è¯­è¨€")
            modifications.append("å¢åŠ è§£é‡Šå’ŒèƒŒæ™¯ä¿¡æ¯")
        
        # è¯­è¨€å¤æ‚åº¦ä¿®æ”¹å»ºè®®
        if language_complexity_level in [LanguageComplexityLevel.ADVANCED, LanguageComplexityLevel.EXPERT]:
            modifications.append("é™ä½è¯æ±‡å¤æ‚åº¦")
            modifications.append("ç®€åŒ–å¥å­ç»“æ„")
        
        return modifications
    
    def _calculate_confidence(self, safety_score: float, h_score: float, l_score: float) -> float:
        """è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        # åŸºäºå„ç»´åº¦åˆ†æ•°çš„ä¸€è‡´æ€§è®¡ç®—ç½®ä¿¡åº¦
        scores = [safety_score, h_score, l_score]
        variance = np.var(scores)
        mean_score = np.mean(scores)
        
        # æ–¹å·®è¶Šå°ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        confidence = 1.0 - variance
        
        # ç¡®ä¿ç½®ä¿¡åº¦åœ¨åˆç†èŒƒå›´å†…
        return max(0.1, min(0.9, confidence))
    
    def _record_decision(self, decision: ExpressionDecision, text: str, target_audience: str):
        """è®°å½•å†³ç­–å†å²"""
        record = {
            'timestamp': time.time(),
            'text': text[:100] + "..." if len(text) > 100 else text,
            'target_audience': target_audience,
            'decision': decision,
            'text_length': len(text)
        }
        
        self.decision_history.append(record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.decision_history) > 1000:
            self.decision_history = self.decision_history[-500:]
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """è·å–å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.decision_history:
            return {"error": "No decision history available"}
        
        total_decisions = len(self.decision_history)
        approved_decisions = sum(1 for record in self.decision_history 
                               if record['decision'].should_express)
        rejected_decisions = total_decisions - approved_decisions
        
        # å„ç»´åº¦ç»Ÿè®¡
        safety_levels = [record['decision'].safety_level for record in self.decision_history]
        human_reception_levels = [record['decision'].human_reception_level for record in self.decision_history]
        language_complexity_levels = [record['decision'].language_complexity_level for record in self.decision_history]
        
        return {
            'total_decisions': total_decisions,
            'approved_decisions': approved_decisions,
            'rejected_decisions': rejected_decisions,
            'approval_rate': approved_decisions / total_decisions if total_decisions > 0 else 0,
            'safety_level_distribution': self._count_levels(safety_levels),
            'human_reception_level_distribution': self._count_levels(human_reception_levels),
            'language_complexity_level_distribution': self._count_levels(language_complexity_levels)
        }
    
    def _count_levels(self, levels: List) -> Dict[str, int]:
        """ç»Ÿè®¡ç­‰çº§åˆ†å¸ƒ"""
        count_dict = {}
        for level in levels:
            level_name = level.value
            count_dict[level_name] = count_dict.get(level_name, 0) + 1
        return count_dict


def test_expression_arbitrator():
    """æµ‹è¯•è¡¨è¾¾è£å†³å™¨"""
    print("ğŸ§ª æµ‹è¯•V4.0è¡¨è¾¾ä¼¦ç†è£å†³å™¨...")
    
    # åˆ›å»ºè£å†³å™¨
    arbitrator = ExpressionArbitrator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'text': 'è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ–‡æœ¬ã€‚',
            'target_audience': 'general',
            'expected_result': True
        },
        {
            'text': 'è¿™æ˜¯ä¸€ä¸ªåŒ…å«å±é™©è¯æ±‡çš„æ–‡æœ¬ï¼Œå¯èƒ½é€ æˆä¼¤å®³ã€‚',
            'target_audience': 'general',
            'expected_result': False
        },
        {
            'text': 'è¿™æ˜¯ä¸€ä¸ªéå¸¸å¤æ‚çš„æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…å«å¤§é‡ä¸“ä¸šæœ¯è¯­å’Œå¤æ‚çš„ç†è®ºæ¦‚å¿µï¼Œéœ€è¦æ·±å…¥çš„ä¸“ä¸šçŸ¥è¯†æ‰èƒ½ç†è§£ã€‚',
            'target_audience': 'general',
            'expected_result': False
        }
    ]
    
    for i, test_case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}:")
        print(f"æ–‡æœ¬: {test_case['text']}")
        print(f"ç›®æ ‡å—ä¼—: {test_case['target_audience']}")
        
        # åˆ›å»ºæ¨¡æ‹ŸåµŒå…¥
        content_embedding = torch.randn(1, 768)
        
        # è¯„ä¼°è¡¨è¾¾
        decision = arbitrator.evaluate_expression(
            content_embedding, 
            test_case['text'], 
            test_case['target_audience']
        )
        
        print(f"å†³ç­–ç»“æœ: {'é€šè¿‡' if decision.should_express else 'æ‹’ç»'}")
        print(f"å®‰å…¨ç­‰çº§: {decision.safety_level.value}")
        print(f"äººç±»æ¥æ”¶ç­‰çº§: {decision.human_reception_level.value}")
        print(f"è¯­è¨€å¤æ‚åº¦ç­‰çº§: {decision.language_complexity_level.value}")
        print(f"ç½®ä¿¡åº¦: {decision.confidence_score:.3f}")
        print(f"æ¨ç†: {decision.reasoning}")
        print(f"ä¿®æ”¹å»ºè®®: {decision.suggested_modifications}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = arbitrator.get_decision_statistics()
    print(f"\nğŸ“Š å†³ç­–ç»Ÿè®¡:")
    for key, value in stats.items():
        if key != 'decision':
            print(f"  {key}: {value}")


if __name__ == "__main__":
    test_expression_arbitrator() 